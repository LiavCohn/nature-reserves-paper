{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import function\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel('../VisitorEntrancesV3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_origin[df_origin.Site_Name=='Caesarea']\n",
    "df = function.remove_unique_one(df)\n",
    "df = df.drop(df.filter(regex='Season').columns, axis=1)\n",
    "df = df.drop(df.filter(regex='Exceeded').columns, axis=1)\n",
    "df = df.drop(df.filter(regex='isHeatwave').columns, axis=1)\n",
    "df = df.replace({True:1,False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfWithoutLastYearVisits = df.dropna().drop('last_year_visitors',axis=1)\n",
    "dfWithoutLastYearVisits = df.drop('last_year_visitors',axis=1).dropna()\n",
    "dfLastYearVisits = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433, 7)\n",
      "(663, 6)\n"
     ]
    }
   ],
   "source": [
    "print(dfLastYearVisits.shape)\n",
    "print(dfWithoutLastYearVisits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from IPython.display import clear_output\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithoutLastYearVisits.sort_values('Date')\n",
    "X = dfWithoutLastYearVisits.drop(['Israelis_Count'],axis=1)\n",
    "y = dfWithoutLastYearVisits[['Date','Israelis_Count']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size = 0.2)\n",
    "\n",
    "X_train_scaler = MinMaxScaler()\n",
    "X_test_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = X_train_scaler.fit_transform(X_train.drop('Date',axis=1))\n",
    "X_test_scaled = X_test_scaler.fit_transform(X_test.drop('Date',axis=1))\n",
    " \n",
    "X_train_scaled\n",
    "\n",
    "\n",
    "X_train_date = X_train.Date\n",
    "y_train_date = y_train.Date\n",
    "X_test_date = X_test.Date\n",
    "y_test_date = y_test.Date\n",
    "\n",
    "y_train.drop('Date',axis=1,inplace=True)\n",
    "y_test.drop('Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NN model\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train_scaled.shape[1], input_dim=X_train_scaled.shape[1],activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dense(128,activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16,activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "410/424 [============================>.] - ETA: 0s - loss: 1443988.2500 - mae: 928.1855 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 1230302.37500, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 3s 5ms/step - loss: 1433018.3750 - mae: 921.0720 - accuracy: 0.0000e+00 - val_loss: 1230302.3750 - val_mae: 810.7136 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "412/424 [============================>.] - ETA: 0s - loss: 599235.9375 - mae: 492.1323 - accuracy: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 1230302.37500 to 568348.93750, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 1s 3ms/step - loss: 591641.1250 - mae: 491.2735 - accuracy: 0.0000e+00 - val_loss: 568348.9375 - val_mae: 480.7125 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "423/424 [============================>.] - ETA: 0s - loss: 499331.7812 - mae: 482.3997 - accuracy: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 568348.93750 to 537298.87500, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 1s 3ms/step - loss: 498370.7500 - mae: 481.9727 - accuracy: 0.0000e+00 - val_loss: 537298.8750 - val_mae: 476.6764 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "414/424 [============================>.] - ETA: 0s - loss: 477101.6875 - mae: 476.5646 - accuracy: 0.0000e+00\n",
      "Epoch 4: val_loss improved from 537298.87500 to 532255.56250, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 476970.0625 - mae: 476.3000 - accuracy: 0.0000e+00 - val_loss: 532255.5625 - val_mae: 464.5573 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "409/424 [===========================>..] - ETA: 0s - loss: 479930.8125 - mae: 458.6878 - accuracy: 0.0000e+00\n",
      "Epoch 5: val_loss improved from 532255.56250 to 496574.43750, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 1s 3ms/step - loss: 477985.1562 - mae: 459.4322 - accuracy: 0.0000e+00 - val_loss: 496574.4375 - val_mae: 473.7443 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "420/424 [============================>.] - ETA: 0s - loss: 473614.6562 - mae: 476.1924 - accuracy: 0.0000e+00\n",
      "Epoch 6: val_loss did not improve from 496574.43750\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 483206.5625 - mae: 479.8006 - accuracy: 0.0000e+00 - val_loss: 542561.6250 - val_mae: 450.9930 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "414/424 [============================>.] - ETA: 0s - loss: 452523.3125 - mae: 441.6979 - accuracy: 0.0000e+00\n",
      "Epoch 7: val_loss did not improve from 496574.43750\n",
      "424/424 [==============================] - 1s 3ms/step - loss: 458945.2812 - mae: 444.5747 - accuracy: 0.0000e+00 - val_loss: 500625.6562 - val_mae: 449.8748 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/10000\n",
      "418/424 [============================>.] - ETA: 0s - loss: 484387.6250 - mae: 462.3065 - accuracy: 0.0000e+00\n",
      "Epoch 8: val_loss improved from 496574.43750 to 494272.21875, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 480431.5000 - mae: 461.0686 - accuracy: 0.0000e+00 - val_loss: 494272.2188 - val_mae: 449.4941 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/10000\n",
      "424/424 [==============================] - ETA: 0s - loss: 456306.5000 - mae: 454.3687 - accuracy: 0.0000e+00\n",
      "Epoch 9: val_loss improved from 494272.21875 to 488033.50000, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 456306.5000 - mae: 454.3687 - accuracy: 0.0000e+00 - val_loss: 488033.5000 - val_mae: 449.7576 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/10000\n",
      "410/424 [============================>.] - ETA: 0s - loss: 412756.6562 - mae: 433.7564 - accuracy: 0.0000e+00\n",
      "Epoch 10: val_loss improved from 488033.50000 to 476444.12500, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 411467.0938 - mae: 434.4008 - accuracy: 0.0000e+00 - val_loss: 476444.1250 - val_mae: 454.2044 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/10000\n",
      "417/424 [============================>.] - ETA: 0s - loss: 434811.2188 - mae: 431.7724 - accuracy: 0.0000e+00\n",
      "Epoch 11: val_loss improved from 476444.12500 to 473852.06250, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 428489.6250 - mae: 427.9051 - accuracy: 0.0000e+00 - val_loss: 473852.0625 - val_mae: 455.3903 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/10000\n",
      "416/424 [============================>.] - ETA: 0s - loss: 426786.0312 - mae: 435.0559 - accuracy: 0.0000e+00\n",
      "Epoch 12: val_loss did not improve from 473852.06250\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 431060.0625 - mae: 437.7985 - accuracy: 0.0000e+00 - val_loss: 474827.8750 - val_mae: 455.4906 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/10000\n",
      "419/424 [============================>.] - ETA: 0s - loss: 430911.9688 - mae: 435.2658 - accuracy: 0.0000e+00\n",
      "Epoch 13: val_loss did not improve from 473852.06250\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 427716.6562 - mae: 434.3724 - accuracy: 0.0000e+00 - val_loss: 474428.4375 - val_mae: 456.8725 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/10000\n",
      "413/424 [============================>.] - ETA: 0s - loss: 409099.8438 - mae: 426.2613 - accuracy: 0.0000e+00\n",
      "Epoch 14: val_loss improved from 473852.06250 to 469891.21875, saving model to weightsCeasareaWithoutLastYearVisits.h5\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 404585.0938 - mae: 425.1406 - accuracy: 0.0000e+00 - val_loss: 469891.2188 - val_mae: 461.0782 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/10000\n",
      "416/424 [============================>.] - ETA: 0s - loss: 453269.6562 - mae: 454.0522 - accuracy: 0.0000e+00\n",
      "Epoch 15: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 471566.6562 - mae: 459.2253 - accuracy: 0.0000e+00 - val_loss: 480979.6250 - val_mae: 456.0016 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/10000\n",
      "416/424 [============================>.] - ETA: 0s - loss: 454711.3750 - mae: 442.7221 - accuracy: 0.0000e+00\n",
      "Epoch 16: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 448063.2500 - mae: 439.2422 - accuracy: 0.0000e+00 - val_loss: 482830.1875 - val_mae: 455.6833 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/10000\n",
      "414/424 [============================>.] - ETA: 0s - loss: 428525.5938 - mae: 437.7240 - accuracy: 0.0000e+00\n",
      "Epoch 17: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 420852.0312 - mae: 434.1238 - accuracy: 0.0000e+00 - val_loss: 481377.5625 - val_mae: 457.4638 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/10000\n",
      "414/424 [============================>.] - ETA: 0s - loss: 417633.8125 - mae: 428.6925 - accuracy: 0.0000e+00\n",
      "Epoch 18: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 411879.5625 - mae: 425.5774 - accuracy: 0.0000e+00 - val_loss: 476371.6562 - val_mae: 460.8495 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 19/10000\n",
      "411/424 [============================>.] - ETA: 0s - loss: 394389.6562 - mae: 407.6893 - accuracy: 0.0000e+00\n",
      "Epoch 19: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 400223.7500 - mae: 407.9486 - accuracy: 0.0000e+00 - val_loss: 473770.0312 - val_mae: 463.8087 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 20/10000\n",
      "421/424 [============================>.] - ETA: 0s - loss: 441402.1562 - mae: 437.4015 - accuracy: 0.0000e+00\n",
      "Epoch 20: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 438493.4375 - mae: 435.3600 - accuracy: 0.0000e+00 - val_loss: 488258.1250 - val_mae: 456.8010 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 21/10000\n",
      "409/424 [===========================>..] - ETA: 0s - loss: 447880.3750 - mae: 443.3391 - accuracy: 0.0000e+00\n",
      "Epoch 21: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 437524.3438 - mae: 437.3637 - accuracy: 0.0000e+00 - val_loss: 478734.1250 - val_mae: 460.4421 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/10000\n",
      "419/424 [============================>.] - ETA: 0s - loss: 448429.7500 - mae: 438.9481 - accuracy: 0.0000e+00\n",
      "Epoch 22: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 444278.6562 - mae: 436.5018 - accuracy: 0.0000e+00 - val_loss: 491796.9375 - val_mae: 456.8141 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 23/10000\n",
      "422/424 [============================>.] - ETA: 0s - loss: 454306.1250 - mae: 445.6290 - accuracy: 0.0000e+00\n",
      "Epoch 23: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 452526.5312 - mae: 444.5197 - accuracy: 0.0000e+00 - val_loss: 491773.2188 - val_mae: 456.8573 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 24/10000\n",
      "411/424 [============================>.] - ETA: 0s - loss: 414334.9375 - mae: 417.4441 - accuracy: 0.0000e+00\n",
      "Epoch 24: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 422939.2500 - mae: 419.1162 - accuracy: 0.0000e+00 - val_loss: 489884.0312 - val_mae: 457.7546 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 25/10000\n",
      "421/424 [============================>.] - ETA: 0s - loss: 406030.3125 - mae: 421.7450 - accuracy: 0.0000e+00\n",
      "Epoch 25: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 403865.4062 - mae: 420.9607 - accuracy: 0.0000e+00 - val_loss: 477439.5000 - val_mae: 462.6953 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 26/10000\n",
      "417/424 [============================>.] - ETA: 0s - loss: 458157.1875 - mae: 445.3987 - accuracy: 0.0000e+00\n",
      "Epoch 26: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 452901.8750 - mae: 443.4370 - accuracy: 0.0000e+00 - val_loss: 477593.5938 - val_mae: 463.1479 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 27/10000\n",
      "410/424 [============================>.] - ETA: 0s - loss: 421957.7812 - mae: 425.1402 - accuracy: 0.0000e+00\n",
      "Epoch 27: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 413416.3125 - mae: 420.4855 - accuracy: 0.0000e+00 - val_loss: 487415.0625 - val_mae: 459.9023 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 28/10000\n",
      "421/424 [============================>.] - ETA: 0s - loss: 423801.0000 - mae: 434.1611 - accuracy: 0.0000e+00\n",
      "Epoch 28: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 430854.7812 - mae: 437.5211 - accuracy: 0.0000e+00 - val_loss: 478756.6875 - val_mae: 464.6715 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 29/10000\n",
      "422/424 [============================>.] - ETA: 0s - loss: 436449.8438 - mae: 431.5259 - accuracy: 0.0000e+00\n",
      "Epoch 29: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 434663.3438 - mae: 430.5817 - accuracy: 0.0000e+00 - val_loss: 477317.5938 - val_mae: 466.1279 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 30/10000\n",
      "420/424 [============================>.] - ETA: 0s - loss: 419473.5625 - mae: 426.4367 - accuracy: 0.0000e+00\n",
      "Epoch 30: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 416067.7812 - mae: 424.3040 - accuracy: 0.0000e+00 - val_loss: 481538.2188 - val_mae: 464.2172 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 31/10000\n",
      "415/424 [============================>.] - ETA: 0s - loss: 407093.7500 - mae: 421.1176 - accuracy: 0.0000e+00\n",
      "Epoch 31: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 400719.8125 - mae: 417.6205 - accuracy: 0.0000e+00 - val_loss: 480004.5625 - val_mae: 466.7585 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 32/10000\n",
      "421/424 [============================>.] - ETA: 0s - loss: 453498.8750 - mae: 438.8691 - accuracy: 0.0000e+00\n",
      "Epoch 32: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 451392.7188 - mae: 438.4132 - accuracy: 0.0000e+00 - val_loss: 489598.8438 - val_mae: 461.8009 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 33/10000\n",
      "423/424 [============================>.] - ETA: 0s - loss: 436435.9688 - mae: 435.1671 - accuracy: 0.0000e+00\n",
      "Epoch 33: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 5ms/step - loss: 435432.5625 - mae: 434.3400 - accuracy: 0.0000e+00 - val_loss: 498244.0000 - val_mae: 460.0650 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 34/10000\n",
      "417/424 [============================>.] - ETA: 0s - loss: 443296.4375 - mae: 430.3411 - accuracy: 0.0000e+00\n",
      "Epoch 34: val_loss did not improve from 469891.21875\n",
      "424/424 [==============================] - 2s 4ms/step - loss: 441904.5625 - mae: 430.9264 - accuracy: 0.0000e+00 - val_loss: 490415.8438 - val_mae: 459.9410 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 34: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(metrics=['mae','accuracy'], optimizer='adam', loss = 'mean_squared_error')\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=20, verbose=1 )\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, verbose=0 )\n",
    "mcp = ModelCheckpoint(filepath='weightsCeasareaWithoutLastYearVisits.h5', monitor='val_loss', verbose=1 , save_best_only=True, save_weights_only=True)\n",
    "\n",
    "tb = TensorBoard('logs')\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, shuffle=True, epochs=10000,callbacks=[es, rlr, mcp, tb],validation_split=0.2,batch_size=1)\n",
    "clear_output(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weightsCeasareaWithoutLastYearVisits.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 3s 3ms/step\n",
      "\n",
      "mae 415.7016886585164\n",
      "rmse 626.8845164837004\n",
      "std 774.4161430087249\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train_scaled)\n",
    "prediction = prediction.reshape(len(X_train_scaled))\n",
    "print('')\n",
    "res = pd.DataFrame(\n",
    "    data={\n",
    "        'Prediction':prediction,\n",
    "        'Actual': y_train.values.T[0],\n",
    "        },\n",
    "    index=y_train_date\n",
    ")\n",
    "print('mae', mean_absolute_error(res.Prediction, res.Actual))\n",
    "print('rmse',function.get_rmse(res.Prediction, res.Actual))\n",
    "print('std',np.std(res.Actual))\n",
    "\n",
    "res.sort_index(inplace=True)\n",
    "function.plot_line(res.Prediction, res.Actual)\n",
    "# function.plot_residuals(res.Prediction, res.Actual)\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test_scaled)\n",
    "prediction = prediction.reshape(len(X_test_scaled))\n",
    "print('')\n",
    "res = pd.DataFrame(\n",
    "    data={\n",
    "        'Prediction':prediction,\n",
    "        'Actual': y_test.values.T[0],\n",
    "        },\n",
    "    index=y_test_date\n",
    ")\n",
    "print('mae', mean_absolute_error(res.Prediction, res.Actual))\n",
    "print('rmse',function.get_rmse(res.Prediction, res.Actual))\n",
    "print('std',np.std(res.Actual))\n",
    "\n",
    "res.sort_index(inplace=True)\n",
    "function.plot_line(res.Prediction, res.Actual)\n",
    "# function.plot_residuals(res.Prediction, res.Actual)\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime_stability.stability import LimeTabularExplainerOvr\n",
    "\n",
    "class_names=['Israelis_Count']\n",
    "\n",
    "categorical_features = np.argwhere(\n",
    "    np.array([len(set(X_train_scaled[:,x]))\n",
    "    for x in range(X_train_scaled.shape[1])]) <= 2).flatten()\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(categorical_features.shape)\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "explainer = LimeTabularExplainerOvr(np.array(X_train_scaled),\n",
    " feature_names=X_train.drop('Date',axis=1).columns,\n",
    " class_names=class_names, \n",
    " categorical_features=categorical_features, \n",
    " verbose=True,\n",
    " mode='regression'\n",
    " )\n",
    "\n",
    "i = np.random.randint(len(X_test_scaled))\n",
    "print('index ', i, ':: Actual values = ', y_test.Israelis_Count.values[i])\n",
    "print('index ', i, ':: Prediction values = ', prediction.tolist()[i])\n",
    "exp = explainer.explain_instance((X_test_scaled[i]),model.predict,num_features=100)\n",
    "exp.show_in_notebook(show_table=True)\n",
    "function.outputLimeAsDf(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function.getLimeAvg(X_test_scaled=X_test_scaled,X_train_scaled=X_train_scaled,X_train=X_train,model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21399d2563c2f2b8a9c8e6b3ef80a12e728513ae0f52517e9a59773528b494c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
