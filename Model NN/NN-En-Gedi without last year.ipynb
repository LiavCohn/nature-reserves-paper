{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import function\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel('../VisitorEntrancesV3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_origin[df_origin.Site_Name=='En Gedi']\n",
    "df = function.remove_unique_one(df)\n",
    "df = df.drop(df.filter(regex='Season').columns, axis=1)\n",
    "df = df.drop(df.filter(regex='Exceeded').columns, axis=1)\n",
    "df = df.drop(df.filter(regex='isHeatwave').columns, axis=1)\n",
    "df = df.replace({True:1,False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfWithoutLastYearVisits = df.dropna().drop('last_year_visitors',axis=1)\n",
    "dfWithoutLastYearVisits = df.drop('last_year_visitors',axis=1).dropna()\n",
    "dfLastYearVisits = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1002, 7)\n",
      "(1381, 6)\n"
     ]
    }
   ],
   "source": [
    "print(dfLastYearVisits.shape)\n",
    "print(dfWithoutLastYearVisits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from IPython.display import clear_output\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithoutLastYearVisits.sort_values('Date')\n",
    "X = dfWithoutLastYearVisits.drop(['Israelis_Count'],axis=1)\n",
    "y = dfWithoutLastYearVisits[['Date','Israelis_Count']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size = 0.2)\n",
    "\n",
    "X_train_scaler = MinMaxScaler()\n",
    "X_test_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = X_train_scaler.fit_transform(X_train.drop('Date',axis=1))\n",
    "X_test_scaled = X_test_scaler.fit_transform(X_test.drop('Date',axis=1))\n",
    " \n",
    "X_train_scaled\n",
    "\n",
    "\n",
    "X_train_date = X_train.Date\n",
    "y_train_date = y_train.Date\n",
    "X_test_date = X_test.Date\n",
    "y_test_date = y_test.Date\n",
    "\n",
    "y_train.drop('Date',axis=1,inplace=True)\n",
    "y_test.drop('Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NN model\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train_scaled.shape[1], input_dim=X_train_scaled.shape[1],activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dense(516,activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(516,activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64,activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu',activity_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "882/883 [============================>.] - ETA: 0s - loss: 696729.3750 - mae: 629.0104 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 389574.93750, saving model to weightsEnGediWithoutLastYearVisits.h5\n",
      "883/883 [==============================] - 5s 5ms/step - loss: 696508.5000 - mae: 629.0916 - accuracy: 0.0000e+00 - val_loss: 389574.9375 - val_mae: 445.9707 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "876/883 [============================>.] - ETA: 0s - loss: 570876.8750 - mae: 573.3528 - accuracy: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 389574.93750 to 371988.81250, saving model to weightsEnGediWithoutLastYearVisits.h5\n",
      "883/883 [==============================] - 4s 4ms/step - loss: 575833.5625 - mae: 575.1067 - accuracy: 0.0000e+00 - val_loss: 371988.8125 - val_mae: 442.5922 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "876/883 [============================>.] - ETA: 0s - loss: 582290.6875 - mae: 570.4481 - accuracy: 0.0000e+00\n",
      "Epoch 3: val_loss did not improve from 371988.81250\n",
      "883/883 [==============================] - 4s 5ms/step - loss: 580711.0000 - mae: 569.5569 - accuracy: 0.0000e+00 - val_loss: 374863.4062 - val_mae: 452.3493 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "874/883 [============================>.] - ETA: 0s - loss: 568328.8750 - mae: 569.3024 - accuracy: 0.0000e+00\n",
      "Epoch 4: val_loss did not improve from 371988.81250\n",
      "883/883 [==============================] - 5s 5ms/step - loss: 572783.3750 - mae: 570.5331 - accuracy: 0.0000e+00 - val_loss: 397372.3438 - val_mae: 482.6120 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "879/883 [============================>.] - ETA: 0s - loss: 581295.5625 - mae: 569.0684 - accuracy: 0.0000e+00\n",
      "Epoch 5: val_loss did not improve from 371988.81250\n",
      "883/883 [==============================] - 5s 6ms/step - loss: 580184.3125 - mae: 568.9130 - accuracy: 0.0000e+00 - val_loss: 383544.6250 - val_mae: 429.1813 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "881/883 [============================>.] - ETA: 0s - loss: 574200.6875 - mae: 575.7081 - accuracy: 0.0000e+00\n",
      "Epoch 6: val_loss did not improve from 371988.81250\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 573842.0000 - mae: 575.8080 - accuracy: 0.0000e+00 - val_loss: 413325.2188 - val_mae: 507.7784 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "875/883 [============================>.] - ETA: 0s - loss: 573151.8750 - mae: 571.2719 - accuracy: 0.0000e+00\n",
      "Epoch 7: val_loss improved from 371988.81250 to 367513.28125, saving model to weightsEnGediWithoutLastYearVisits.h5\n",
      "883/883 [==============================] - 7s 8ms/step - loss: 568561.0625 - mae: 567.6862 - accuracy: 0.0000e+00 - val_loss: 367513.2812 - val_mae: 435.3681 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/10000\n",
      "878/883 [============================>.] - ETA: 0s - loss: 574299.0625 - mae: 561.0490 - accuracy: 0.0000e+00\n",
      "Epoch 8: val_loss did not improve from 367513.28125\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 575373.2500 - mae: 560.7541 - accuracy: 0.0000e+00 - val_loss: 368036.8750 - val_mae: 438.5860 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/10000\n",
      "880/883 [============================>.] - ETA: 0s - loss: 568903.9375 - mae: 559.2892 - accuracy: 0.0000e+00\n",
      "Epoch 9: val_loss did not improve from 367513.28125\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 573051.6875 - mae: 560.5648 - accuracy: 0.0000e+00 - val_loss: 369886.3125 - val_mae: 442.6200 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/10000\n",
      "877/883 [============================>.] - ETA: 0s - loss: 561976.3125 - mae: 560.6827 - accuracy: 0.0000e+00\n",
      "Epoch 10: val_loss did not improve from 367513.28125\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 570950.3125 - mae: 563.3914 - accuracy: 0.0000e+00 - val_loss: 377223.3125 - val_mae: 455.1016 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/10000\n",
      "879/883 [============================>.] - ETA: 0s - loss: 531273.8125 - mae: 549.1526 - accuracy: 0.0000e+00\n",
      "Epoch 11: val_loss did not improve from 367513.28125\n",
      "883/883 [==============================] - 7s 8ms/step - loss: 535559.8750 - mae: 551.0311 - accuracy: 0.0000e+00 - val_loss: 374182.0938 - val_mae: 452.3605 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/10000\n",
      "882/883 [============================>.] - ETA: 0s - loss: 546780.0625 - mae: 553.9684 - accuracy: 0.0000e+00\n",
      "Epoch 12: val_loss did not improve from 367513.28125\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 546271.6875 - mae: 553.6779 - accuracy: 0.0000e+00 - val_loss: 469862.7812 - val_mae: 559.9144 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/10000\n",
      "880/883 [============================>.] - ETA: 0s - loss: 549051.6250 - mae: 554.1062 - accuracy: 0.0000e+00\n",
      "Epoch 13: val_loss improved from 367513.28125 to 366141.03125, saving model to weightsEnGediWithoutLastYearVisits.h5\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 547610.6250 - mae: 553.2819 - accuracy: 0.0000e+00 - val_loss: 366141.0312 - val_mae: 447.1856 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/10000\n",
      "879/883 [============================>.] - ETA: 0s - loss: 540571.0000 - mae: 552.0652 - accuracy: 0.0000e+00\n",
      "Epoch 14: val_loss did not improve from 366141.03125\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 547723.9375 - mae: 553.9405 - accuracy: 0.0000e+00 - val_loss: 367999.4062 - val_mae: 436.3727 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/10000\n",
      "880/883 [============================>.] - ETA: 0s - loss: 512263.4688 - mae: 533.7820 - accuracy: 0.0000e+00\n",
      "Epoch 15: val_loss improved from 366141.03125 to 352844.93750, saving model to weightsEnGediWithoutLastYearVisits.h5\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 518545.0938 - mae: 535.8748 - accuracy: 0.0000e+00 - val_loss: 352844.9375 - val_mae: 420.6361 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 16/10000\n",
      "878/883 [============================>.] - ETA: 0s - loss: 521618.0000 - mae: 541.6340 - accuracy: 0.0000e+00\n",
      "Epoch 16: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 520319.2500 - mae: 541.1904 - accuracy: 0.0000e+00 - val_loss: 359790.9375 - val_mae: 440.7725 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 17/10000\n",
      "879/883 [============================>.] - ETA: 0s - loss: 518406.5312 - mae: 540.3113 - accuracy: 0.0000e+00\n",
      "Epoch 17: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 518484.9375 - mae: 540.8844 - accuracy: 0.0000e+00 - val_loss: 396728.6250 - val_mae: 490.7987 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 18/10000\n",
      "881/883 [============================>.] - ETA: 0s - loss: 500135.2188 - mae: 527.1317 - accuracy: 0.0000e+00\n",
      "Epoch 18: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 499041.8750 - mae: 526.1279 - accuracy: 0.0000e+00 - val_loss: 385718.0938 - val_mae: 478.3372 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 19/10000\n",
      "880/883 [============================>.] - ETA: 0s - loss: 503976.6250 - mae: 537.0823 - accuracy: 0.0000e+00\n",
      "Epoch 19: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 504199.9062 - mae: 537.6016 - accuracy: 0.0000e+00 - val_loss: 357109.4062 - val_mae: 430.2933 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 20/10000\n",
      "876/883 [============================>.] - ETA: 0s - loss: 519199.1875 - mae: 535.8804 - accuracy: 0.0000e+00\n",
      "Epoch 20: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 519614.1875 - mae: 536.8086 - accuracy: 0.0000e+00 - val_loss: 371404.6250 - val_mae: 422.9868 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 21/10000\n",
      "883/883 [==============================] - ETA: 0s - loss: 489700.8125 - mae: 526.4919 - accuracy: 0.0000e+00\n",
      "Epoch 21: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 489700.8125 - mae: 526.4919 - accuracy: 0.0000e+00 - val_loss: 362992.0625 - val_mae: 450.7225 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/10000\n",
      "881/883 [============================>.] - ETA: 0s - loss: 525518.9375 - mae: 539.8208 - accuracy: 0.0000e+00\n",
      "Epoch 22: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 524699.0625 - mae: 539.4002 - accuracy: 0.0000e+00 - val_loss: 375316.3438 - val_mae: 469.0241 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 23/10000\n",
      "881/883 [============================>.] - ETA: 0s - loss: 492981.1875 - mae: 519.4940 - accuracy: 0.0000e+00\n",
      "Epoch 23: val_loss did not improve from 352844.93750\n",
      "883/883 [==============================] - 7s 7ms/step - loss: 492306.3125 - mae: 519.2574 - accuracy: 0.0000e+00 - val_loss: 357664.1562 - val_mae: 442.0038 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 24/10000\n",
      "880/883 [============================>.] - ETA: 0s - loss: 507451.3125 - mae: 528.8145 - accuracy: 0.0000e+00\n",
      "Epoch 24: val_loss improved from 352844.93750 to 350986.46875, saving model to weightsEnGediWithoutLastYearVisits.h5\n",
      "883/883 [==============================] - 7s 7ms/step - loss: 507033.9375 - mae: 528.8055 - accuracy: 0.0000e+00 - val_loss: 350986.4688 - val_mae: 426.7707 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 25/10000\n",
      "883/883 [==============================] - ETA: 0s - loss: 510618.8438 - mae: 524.5539 - accuracy: 0.0000e+00\n",
      "Epoch 25: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 510618.8438 - mae: 524.5539 - accuracy: 0.0000e+00 - val_loss: 356218.8125 - val_mae: 428.1958 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 26/10000\n",
      "876/883 [============================>.] - ETA: 0s - loss: 531060.5000 - mae: 524.8918 - accuracy: 0.0000e+00\n",
      "Epoch 26: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 527472.9375 - mae: 522.4549 - accuracy: 0.0000e+00 - val_loss: 358635.2500 - val_mae: 439.1939 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 27/10000\n",
      "876/883 [============================>.] - ETA: 0s - loss: 501339.3125 - mae: 518.6189 - accuracy: 0.0000e+00\n",
      "Epoch 27: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 502502.5938 - mae: 519.6720 - accuracy: 0.0000e+00 - val_loss: 351875.4062 - val_mae: 426.0226 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 28/10000\n",
      "881/883 [============================>.] - ETA: 0s - loss: 502500.8438 - mae: 522.6292 - accuracy: 0.0000e+00\n",
      "Epoch 28: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 501389.4375 - mae: 521.5696 - accuracy: 0.0000e+00 - val_loss: 357275.0312 - val_mae: 436.9517 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 29/10000\n",
      "878/883 [============================>.] - ETA: 0s - loss: 491989.6562 - mae: 526.9891 - accuracy: 0.0000e+00\n",
      "Epoch 29: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 489992.9375 - mae: 525.7120 - accuracy: 0.0000e+00 - val_loss: 366473.7500 - val_mae: 420.9100 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 30/10000\n",
      "878/883 [============================>.] - ETA: 0s - loss: 513972.7812 - mae: 534.3063 - accuracy: 0.0000e+00\n",
      "Epoch 30: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 511669.3438 - mae: 533.0305 - accuracy: 0.0000e+00 - val_loss: 356496.6875 - val_mae: 432.1943 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 31/10000\n",
      "878/883 [============================>.] - ETA: 0s - loss: 496092.2500 - mae: 520.6146 - accuracy: 0.0000e+00\n",
      "Epoch 31: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 495885.4688 - mae: 520.7532 - accuracy: 0.0000e+00 - val_loss: 358163.0312 - val_mae: 431.0651 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 32/10000\n",
      "876/883 [============================>.] - ETA: 0s - loss: 499582.5312 - mae: 524.9201 - accuracy: 0.0000e+00\n",
      "Epoch 32: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 504368.8438 - mae: 526.7742 - accuracy: 0.0000e+00 - val_loss: 378184.5000 - val_mae: 473.3591 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 33/10000\n",
      "882/883 [============================>.] - ETA: 0s - loss: 496830.8125 - mae: 528.7236 - accuracy: 0.0000e+00\n",
      "Epoch 33: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 496659.1562 - mae: 528.7875 - accuracy: 0.0000e+00 - val_loss: 360701.9375 - val_mae: 448.0457 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 34/10000\n",
      "881/883 [============================>.] - ETA: 0s - loss: 496062.1562 - mae: 518.0982 - accuracy: 0.0000e+00\n",
      "Epoch 34: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 498015.9062 - mae: 519.1124 - accuracy: 0.0000e+00 - val_loss: 365381.9688 - val_mae: 450.8014 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 35/10000\n",
      "875/883 [============================>.] - ETA: 0s - loss: 508269.9688 - mae: 523.8579 - accuracy: 0.0000e+00\n",
      "Epoch 35: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 5s 6ms/step - loss: 506774.0000 - mae: 523.3622 - accuracy: 0.0000e+00 - val_loss: 357580.7812 - val_mae: 436.8550 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 36/10000\n",
      "878/883 [============================>.] - ETA: 0s - loss: 488496.2500 - mae: 514.0330 - accuracy: 0.0000e+00\n",
      "Epoch 36: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 6ms/step - loss: 485952.6562 - mae: 512.0695 - accuracy: 0.0000e+00 - val_loss: 360636.0312 - val_mae: 433.1479 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 37/10000\n",
      "880/883 [============================>.] - ETA: 0s - loss: 511618.5938 - mae: 522.6429 - accuracy: 0.0000e+00\n",
      "Epoch 37: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 6ms/step - loss: 510450.3750 - mae: 521.7767 - accuracy: 0.0000e+00 - val_loss: 362847.2188 - val_mae: 440.2864 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 38/10000\n",
      "880/883 [============================>.] - ETA: 0s - loss: 521149.6250 - mae: 534.7300 - accuracy: 0.0000e+00\n",
      "Epoch 38: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 5s 6ms/step - loss: 522531.0312 - mae: 535.6710 - accuracy: 0.0000e+00 - val_loss: 361649.8438 - val_mae: 444.9190 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 39/10000\n",
      "879/883 [============================>.] - ETA: 0s - loss: 502310.1562 - mae: 520.0984 - accuracy: 0.0000e+00\n",
      "Epoch 39: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 5s 6ms/step - loss: 501387.9375 - mae: 520.1343 - accuracy: 0.0000e+00 - val_loss: 360923.8438 - val_mae: 425.0386 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 40/10000\n",
      "883/883 [==============================] - ETA: 0s - loss: 493181.5000 - mae: 517.4293 - accuracy: 0.0000e+00\n",
      "Epoch 40: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 7ms/step - loss: 493181.5000 - mae: 517.4293 - accuracy: 0.0000e+00 - val_loss: 351465.4688 - val_mae: 429.5938 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 41/10000\n",
      "876/883 [============================>.] - ETA: 0s - loss: 478800.5625 - mae: 518.5369 - accuracy: 0.0000e+00\n",
      "Epoch 41: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 6ms/step - loss: 477816.5000 - mae: 518.3943 - accuracy: 0.0000e+00 - val_loss: 379971.3438 - val_mae: 466.0757 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 42/10000\n",
      "881/883 [============================>.] - ETA: 0s - loss: 515263.7188 - mae: 535.9677 - accuracy: 0.0000e+00\n",
      "Epoch 42: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 5s 6ms/step - loss: 514175.7500 - mae: 535.1007 - accuracy: 0.0000e+00 - val_loss: 382825.8438 - val_mae: 424.2738 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 43/10000\n",
      "877/883 [============================>.] - ETA: 0s - loss: 500681.5938 - mae: 524.7914 - accuracy: 0.0000e+00\n",
      "Epoch 43: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 6ms/step - loss: 498877.6875 - mae: 523.7215 - accuracy: 0.0000e+00 - val_loss: 355070.1562 - val_mae: 436.2473 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 44/10000\n",
      "874/883 [============================>.] - ETA: 0s - loss: 501128.7812 - mae: 524.4168 - accuracy: 0.0000e+00\n",
      "Epoch 44: val_loss did not improve from 350986.46875\n",
      "883/883 [==============================] - 6s 6ms/step - loss: 509632.2500 - mae: 526.5599 - accuracy: 0.0000e+00 - val_loss: 364089.6875 - val_mae: 433.0929 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 44: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(metrics=['mae','accuracy'], optimizer='adam', loss = 'mean_squared_error')\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=20, verbose=1 )\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, verbose=0 )\n",
    "mcp = ModelCheckpoint(filepath='weightsEnGediWithoutLastYearVisits.h5', monitor='val_loss', verbose=1 , save_best_only=True, save_weights_only=True)\n",
    "\n",
    "tb = TensorBoard('logs')\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, shuffle=True, epochs=10000,callbacks=[es, rlr, mcp, tb],validation_split=0.2,batch_size=1)\n",
    "clear_output(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weightsEnGediWithoutLastYearVisits.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 3s 3ms/step\n",
      "\n",
      "mae 477.49948125645733\n",
      "rmse 647.3270303046688\n",
      "std 708.2008142467268\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train_scaled)\n",
    "prediction = prediction.reshape(len(X_train_scaled))\n",
    "print('')\n",
    "res = pd.DataFrame(\n",
    "    data={\n",
    "        'Prediction':prediction,\n",
    "        'Actual': y_train.values.T[0],\n",
    "        },\n",
    "    index=y_train_date\n",
    ")\n",
    "print('mae', mean_absolute_error(res.Prediction, res.Actual))\n",
    "print('rmse',function.get_rmse(res.Prediction, res.Actual))\n",
    "print('std',np.std(res.Actual))\n",
    "\n",
    "res.sort_index(inplace=True)\n",
    "function.plot_line(res.Prediction, res.Actual)\n",
    "# function.plot_residuals(res.Prediction, res.Actual)\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test_scaled)\n",
    "prediction = prediction.reshape(len(X_test_scaled))\n",
    "print('')\n",
    "res = pd.DataFrame(\n",
    "    data={\n",
    "        'Prediction':prediction,\n",
    "        'Actual': y_test.values.T[0],\n",
    "        },\n",
    "    index=y_test_date\n",
    ")\n",
    "print('mae', mean_absolute_error(res.Prediction, res.Actual))\n",
    "print('rmse',function.get_rmse(res.Prediction, res.Actual))\n",
    "print('std',np.std(res.Actual))\n",
    "\n",
    "res.sort_index(inplace=True)\n",
    "function.plot_line(res.Prediction, res.Actual)\n",
    "# function.plot_residuals(res.Prediction, res.Actual)\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime_stability.stability import LimeTabularExplainerOvr\n",
    "\n",
    "class_names=['Israelis_Count']\n",
    "\n",
    "categorical_features = np.argwhere(\n",
    "    np.array([len(set(X_train_scaled[:,x]))\n",
    "    for x in range(X_train_scaled.shape[1])]) <= 2).flatten()\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(categorical_features.shape)\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "explainer = LimeTabularExplainerOvr(np.array(X_train_scaled),\n",
    " feature_names=X_train.drop('Date',axis=1).columns,\n",
    " class_names=class_names, \n",
    " categorical_features=categorical_features, \n",
    " verbose=True,\n",
    " mode='regression'\n",
    " )\n",
    "\n",
    "i = np.random.randint(len(X_test_scaled))\n",
    "print('index ', i, ':: Actual values = ', y_test.Israelis_Count.values[i])\n",
    "print('index ', i, ':: Prediction values = ', prediction.tolist()[i])\n",
    "exp = explainer.explain_instance((X_test_scaled[i]),model.predict,num_features=100)\n",
    "exp.show_in_notebook(show_table=True)\n",
    "function.outputLimeAsDf(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function.getLimeAvg(X_test_scaled=X_test_scaled,X_train_scaled=X_train_scaled,X_train=X_train,model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21399d2563c2f2b8a9c8e6b3ef80a12e728513ae0f52517e9a59773528b494c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
